**WELCOME**

This program runs a simulated predator/prey environment where many agents locally execute actions generated by a single DQN for each population based on the agent's state. The code is split over multiple files, with [ai.py] and [environment.py] housing the most relevant logic. There is a set of hyperparameters and constants which you can find and set in [main.py] under the [Constants] class.

**USER INPUT GUIDE**
**KEY**          ->       **EFFECT**

Tab              ->       enables or disables world rendering (when disabled, plots will still show if a record in score has been surpassed)
Up and Down      ->       increase or decrease epsilon by 0.1 for both predators and prey
Left and Right   ->       increase or decrease speed of simulation (SLOW, FAST, UNLIMITED)
S                ->       saves predator and prey model to disk
Left Shift       ->       don't press it. probably does nothing. might break stuff.


## TODO
1. Add constants to screen and be able to turn them off
2. Add GA stats to screen (gen, mutations, etc.)
3. Support prey learning again
4. Communication
7. make plots nice (seaborn)
8. save and load record stats for saving threshold.